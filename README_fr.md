<div align="center">

<img src="img/markdiffusion-color-1.jpg" style="width: 65%;"/>

# Une Bo√Æte √† Outils Open-Source pour le Tatouage Num√©rique G√©n√©ratif des Mod√®les de Diffusion Latente

[![Homepage](https://img.shields.io/badge/Homepage-5F259F?style=for-the-badge&logo=homepage&logoColor=white)](https://generative-watermark.github.io/)
[![Paper](https://img.shields.io/badge/Paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.10569)
[![HF Models](https://img.shields.io/badge/HF--Models-%23FFD14D?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/Generative-Watermark-Toolkits) 

**Versions linguistiques :** [English](README.md) | [‰∏≠Êñá](README_zh.md) | [Fran√ßais](README_fr.md) | [Espa√±ol](README_es.md)

</div>

> üî• **En tant que projet r√©cemment publi√©, nous accueillons les PR !** Si vous avez impl√©ment√© un algorithme de tatouage num√©rique LDM ou si vous √™tes int√©ress√© √† en contribuer un, nous serions ravis de l'inclure dans MarkDiffusion. Rejoignez notre communaut√© et aidez √† rendre le tatouage num√©rique g√©n√©ratif plus accessible √† tous !

## Sommaire
- [Remarques](#-remarques)
- [Mises √† jour](#-mises-√†-jour)
- [Introduction √† MarkDiffusion](#introduction-√†-markdiffusion)
  - [Vue d'ensemble](#vue-densemble)
  - [Caract√©ristiques cl√©s](#caract√©ristiques-cl√©s)
  - [Algorithmes impl√©ment√©s](#algorithmes-impl√©ment√©s)
  - [Module d'√©valuation](#module-d√©valuation)
- [Installation](#installation)
- [D√©marrage rapide](#d√©marrage-rapide)
- [Comment utiliser la bo√Æte √† outils](#comment-utiliser-la-bo√Æte-√†-outils)
  - [G√©n√©ration et d√©tection de m√©dias tatou√©s](#g√©n√©ration-et-d√©tection-de-m√©dias-tatou√©s)
  - [Visualisation des m√©canismes de tatouage](#visualisation-des-m√©canismes-de-tatouage)
  - [Pipelines d'√©valuation](#pipelines-d√©valuation)
- [Citation](#citation)

## ‚ùó‚ùó‚ùó Remarques
Au fur et √† mesure que le contenu du d√©p√¥t MarkDiffusion s'enrichit et que sa taille augmente, nous avons cr√©√© un d√©p√¥t de stockage de mod√®les sur Hugging Face appel√© [Generative-Watermark-Toolkits](https://huggingface.co/Generative-Watermark-Toolkits) pour faciliter l'utilisation. Ce d√©p√¥t contient divers mod√®les par d√©faut pour les algorithmes de tatouage num√©rique qui impliquent des mod√®les auto-entra√Æn√©s. Nous avons supprim√© les poids des mod√®les des dossiers `ckpts/` correspondants de ces algorithmes de tatouage dans le d√©p√¥t principal. **Lors de l'utilisation du code, veuillez d'abord t√©l√©charger les mod√®les correspondants depuis le d√©p√¥t Hugging Face selon les chemins de configuration et les enregistrer dans le r√©pertoire `ckpts/` avant d'ex√©cuter le code.**

## üî• Mises √† jour
üéØ **(2025.10.10)** Ajout des outils d'attaque d'image *Mask, Overlay, AdaptiveNoiseInjection*, merci √† Zheyu Fu pour sa PR !

üéØ **(2025.10.09)** Ajout des outils d'attaque vid√©o *VideoCodecAttack, FrameRateAdapter, FrameInterpolationAttack*, merci √† Luyang Si pour sa PR !

üéØ **(2025.10.08)** Ajout des analyseurs de qualit√© d'image *SSIM, BRISQUE, VIF, FSIM*, merci √† Huan Wang pour sa PR !

‚ú® **(2025.10.07)** Ajout de la m√©thode de tatouage [SFW](https://arxiv.org/pdf/2509.07647), merci √† Huan Wang pour sa PR !

‚ú® **(2025.10.07)** Ajout de la m√©thode de tatouage [VideoMark](https://arxiv.org/abs/2504.16359), merci √† Hanqian Li pour sa PR !

‚ú® **(2025.9.29)** Ajout de la m√©thode de tatouage [GaussMarker](https://arxiv.org/abs/2506.11444), merci √† Luyang Si pour sa PR !

## Introduction √† MarkDiffusion

### Vue d'ensemble

MarkDiffusion est une bo√Æte √† outils Python open-source pour le tatouage num√©rique g√©n√©ratif des mod√®les de diffusion latente. Alors que l'utilisation des mod√®les g√©n√©ratifs bas√©s sur la diffusion s'√©tend, garantir l'authenticit√© et l'origine des m√©dias g√©n√©r√©s devient crucial. MarkDiffusion simplifie l'acc√®s, la compr√©hension et l'√©valuation des technologies de tatouage num√©rique, les rendant accessibles tant aux chercheurs qu'√† la communaut√© au sens large. *Remarque : si vous √™tes int√©ress√© par le tatouage LLM (tatouage de texte), veuillez vous r√©f√©rer √† la bo√Æte √† outils [MarkLLM](https://github.com/THU-BPM/MarkLLM) de notre groupe.*

La bo√Æte √† outils comprend trois composants cl√©s : un cadre d'impl√©mentation unifi√© pour des int√©grations rationalis√©es d'algorithmes de tatouage et des interfaces conviviales ; une suite de visualisation de m√©canismes qui pr√©sente intuitivement les motifs de tatouage ajout√©s et extraits pour aider √† la compr√©hension du public ; et un module d'√©valuation complet offrant des impl√©mentations standard de 24 outils couvrant trois aspects essentiels ‚Äî d√©tectabilit√©, robustesse et qualit√© de sortie, plus 8 pipelines d'√©valuation automatis√©s.

<img src="img/fig1_overview.png" alt="MarkDiffusion Overview" style="zoom:50%;" />

### Caract√©ristiques cl√©s

- **Cadre d'impl√©mentation unifi√© :** MarkDiffusion fournit une architecture modulaire prenant en charge huit algorithmes de tatouage d'image/vid√©o g√©n√©ratifs de pointe pour les LDM.

- **Support algorithmique complet :** Impl√©mente actuellement 8 algorithmes de tatouage de deux cat√©gories principales : m√©thodes bas√©es sur les motifs (Tree-Ring, Ring-ID, ROBIN, WIND) et m√©thodes bas√©es sur les cl√©s (Gaussian-Shading, PRC, SEAL, VideoShield).

- **Solutions de visualisation :** La bo√Æte √† outils comprend des outils de visualisation personnalis√©s qui permettent des vues claires et perspicaces sur le fonctionnement des diff√©rents algorithmes de tatouage dans divers sc√©narios. Ces visualisations aident √† d√©mystifier les m√©canismes des algorithmes, les rendant plus compr√©hensibles pour les utilisateurs.

- **Module d'√©valuation :** Avec 20 outils d'√©valuation couvrant la d√©tectabilit√©, la robustesse et l'impact sur la qualit√© de sortie, MarkDiffusion fournit des capacit√©s d'√©valuation compl√®tes. Il comprend 5 pipelines d'√©valuation automatis√©s : Pipeline de d√©tection de tatouage, Pipeline d'analyse de qualit√© d'image, Pipeline d'analyse de qualit√© vid√©o et outils d'√©valuation de robustesse sp√©cialis√©s.

### Algorithmes impl√©ment√©s

| **Algorithme** | **Cat√©gorie** | **Cible** | **R√©f√©rence** |
|---------------|-------------|------------|---------------|
| Tree-Ring | Motif | Image | [Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030) |
| Ring-ID | Motif | Image | [RingID: Rethinking Tree-Ring Watermarking for Enhanced Multi-Key Identification](https://arxiv.org/abs/2404.14055) |
| ROBIN | Motif | Image | [ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization](https://arxiv.org/abs/2411.03862) |
| WIND | Motif | Image | [Hidden in the Noise: Two-Stage Robust Watermarking for Images](https://arxiv.org/abs/2412.04653) |
| SFW | Motif | Image | [Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity](https://arxiv.org/abs/2509.07647) |
| Gaussian-Shading | Cl√© | Image | [Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956) |
| GaussMarker | Cl√© | Image | [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444) |
| PRC | Cl√© | Image | [An undetectable watermark for generative image models](https://arxiv.org/abs/2410.07369) |
| SEAL | Cl√© | Image | [SEAL: Semantic Aware Image Watermarking](https://arxiv.org/abs/2503.12172) |
| VideoShield | Cl√© | Vid√©o | [VideoShield: Regulating Diffusion-based Video Generation Models via Watermarking](https://arxiv.org/abs/2501.14195) |
| VideoMark | Cl√© | Vid√©o | [VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models](https://arxiv.org/abs/2504.16359) |

### Module d'√©valuation
#### Pipelines d'√©valuation

MarkDiffusion prend en charge huit pipelines, deux pour la d√©tection (WatermarkedMediaDetectionPipeline et UnWatermarkedMediaDetectionPipeline), et six pour l'analyse de qualit√©. Le tableau ci-dessous d√©taille les pipelines d'analyse de qualit√©.

| **Pipeline d'analyse de qualit√©** | **Type d'entr√©e** | **Donn√©es requises** | **M√©triques applicables** |  
| --- | --- | --- | --- |
| DirectImageQualityAnalysisPipeline | Image unique | Image tatou√©e/non tatou√©e g√©n√©r√©e | M√©triques pour l'√©valuation d'image unique | 
| ReferencedImageQualityAnalysisPipeline | Image + contenu de r√©f√©rence | Image tatou√©e/non tatou√©e g√©n√©r√©e + image/texte de r√©f√©rence | M√©triques n√©cessitant un calcul entre image unique et contenu de r√©f√©rence (texte/image) | 
| GroupImageQualityAnalysisPipeline | Ensemble d'images (+ ensemble d'images de r√©f√©rence) | Ensemble d'images tatou√©es/non tatou√©es g√©n√©r√©es (+ ensemble d'images de r√©f√©rence) | M√©triques n√©cessitant un calcul sur des ensembles d'images | 
| RepeatImageQualityAnalysisPipeline | Ensemble d'images | Ensemble d'images tatou√©es/non tatou√©es g√©n√©r√©es de mani√®re r√©p√©t√©e | M√©triques pour √©valuer des ensembles d'images g√©n√©r√©es de mani√®re r√©p√©t√©e | 
| ComparedImageQualityAnalysisPipeline | Deux images pour comparaison | Images tatou√©es et non tatou√©es g√©n√©r√©es | M√©triques mesurant les diff√©rences entre deux images | 
| DirectVideoQualityAnalysisPipeline | Vid√©o unique | Ensemble de cadres vid√©o g√©n√©r√©s | M√©triques pour l'√©valuation vid√©o globale |

#### Outils d'√©valuation

| **Nom de l'outil** | **Cat√©gorie d'√©valuation** | **Description de la fonction** | **M√©triques de sortie** |
| --- | --- | --- | --- |
| FundamentalSuccessRateCalculator | D√©tectabilit√© | Calculer les m√©triques de classification pour la d√©tection de tatouage √† seuil fixe | Diverses m√©triques de classification |
| DynamicThresholdSuccessRateCalculator | D√©tectabilit√© | Calculer les m√©triques de classification pour la d√©tection de tatouage √† seuil dynamique | Diverses m√©triques de classification |
| **Outils d'attaque d'image** | | | |
| Rotation | Robustesse (Image) | Attaque par rotation d'image, testant la r√©sistance du tatouage aux transformations de rotation | Images/cadres pivot√©s |
| CrSc (Crop & Scale) | Robustesse (Image) | Attaque par recadrage et mise √† l'√©chelle, √©valuant la robustesse du tatouage aux changements de taille | Images/cadres recadr√©s/redimensionn√©s |
| GaussianNoise | Robustesse (Image) | Attaque par bruit gaussien, testant la r√©sistance du tatouage aux interf√©rences de bruit | Images/cadres corrompus par le bruit |
| GaussianBlurring | Robustesse (Image) | Attaque par flou gaussien, √©valuant la r√©sistance du tatouage au traitement de flou | Images/cadres flous |
| JPEGCompression | Robustesse (Image) | Attaque par compression JPEG, testant la robustesse du tatouage √† la compression avec perte | Images/cadres compress√©s |
| Brightness | Robustesse (Image) | Attaque par ajustement de luminosit√©, √©valuant la r√©sistance du tatouage aux changements de luminosit√© | Images/cadres modifi√©s en luminosit√© |
| Mask | Robustesse (Image) | Attaque par masquage d'image, testant la r√©sistance du tatouage √† l'occlusion partielle par des rectangles noirs al√©atoires | Images/cadres masqu√©s |
| Overlay | Robustesse (Image) | Attaque par superposition d'image, testant la r√©sistance du tatouage aux traits et annotations de type graffiti | Images/cadres superpos√©s |
| AdaptiveNoiseInjection | Robustesse (Image) | Attaque par injection de bruit adaptatif, testant la r√©sistance du tatouage au bruit adaptatif au contenu (Gaussien/Sel-poivre/Poisson/Speckle) | Images/cadres bruyants avec bruit adaptatif |
| **Outils d'attaque vid√©o** | | | |
| MPEG4Compression | Robustesse (Vid√©o) | Attaque par compression vid√©o MPEG-4, testant la robustesse du tatouage vid√©o √† la compression | Cadres vid√©o compress√©s |
| FrameAverage | Robustesse (Vid√©o) | Attaque par moyennage de cadres, d√©truisant les tatouages par moyennage inter-cadres | Cadres vid√©o moyenn√©s |
| FrameSwap | Robustesse (Vid√©o) | Attaque par √©change de cadres, testant la robustesse en changeant les s√©quences de cadres | Cadres vid√©o √©chang√©s |
| VideoCodecAttack | Robustesse (Vid√©o) | Attaque par r√©-encodage de codec simulant le transcodage de plateforme (H.264/H.265/VP9/AV1) | Cadres vid√©o r√©-encod√©s |
| FrameRateAdapter | Robustesse (Vid√©o) | Attaque par conversion de fr√©quence d'images qui r√©√©chantillonne les cadres tout en pr√©servant la dur√©e | S√©quence de cadres r√©√©chantillonn√©e |
| FrameInterpolationAttack | Robustesse (Vid√©o) | Attaque par interpolation de cadres ins√©rant des cadres m√©lang√©s pour modifier la densit√© temporelle | Cadres vid√©o interpol√©s |
| **Analyseurs de qualit√© d'image** | | | |
| InceptionScoreCalculator | Qualit√© (Image) | √âvaluer la qualit√© et la diversit√© des images g√©n√©r√©es | Score IS |
| FIDCalculator | Qualit√© (Image) | Distance d'Inception de Fr√©chet, mesurant la diff√©rence de distribution entre images g√©n√©r√©es et r√©elles | Valeur FID |
| LPIPSAnalyzer | Qualit√© (Image) | Similarit√© de patch d'image perceptuelle apprise, √©valuant la qualit√© perceptuelle | Distance LPIPS |
| CLIPScoreCalculator | Qualit√© (Image) | √âvaluation de coh√©rence texte-image bas√©e sur CLIP | Score de similarit√© CLIP |
| PSNRAnalyzer | Qualit√© (Image) | Rapport signal sur bruit de cr√™te, mesurant la distorsion d'image | Valeur PSNR (dB) |
| NIQECalculator | Qualit√© (Image) | √âvaluateur de qualit√© d'image naturelle, √©valuation de qualit√© sans r√©f√©rence | Score NIQE |
| SSIMAnalyzer | Qualit√© (Image) | Indice de similarit√© structurelle entre deux images | Valeur SSIM |
| BRISQUEAnalyzer | Qualit√© (Image) | √âvaluateur de qualit√© spatiale d'image aveugle/sans r√©f√©rence, √©valuant la qualit√© perceptuelle d'une image sans n√©cessiter de r√©f√©rence | Score BRISQUE |
| VIFAnalyzer | Qualit√© (Image) | Analyseur de fid√©lit√© d'information visuelle, comparant une image d√©form√©e avec une image de r√©f√©rence pour quantifier la quantit√© d'information visuelle pr√©serv√©e | Valeur VIF |
| FSIMAnalyzer | Qualit√© (Image) | Analyseur d'indice de similarit√© de caract√©ristiques, comparant la similarit√© structurelle entre deux images bas√©e sur la congruence de phase et la magnitude du gradient | Valeur FSIM |
| **Analyseurs de qualit√© vid√©o** | | | |
| SubjectConsistencyAnalyzer | Qualit√© (Vid√©o) | √âvaluer la coh√©rence des objets sujets dans la vid√©o | Score de coh√©rence du sujet |
| BackgroundConsistencyAnalyzer | Qualit√© (Vid√©o) | √âvaluer la coh√©rence et la stabilit√© de l'arri√®re-plan dans la vid√©o | Score de coh√©rence de l'arri√®re-plan |
| MotionSmoothnessAnalyzer | Qualit√© (Vid√©o) | √âvaluer la fluidit√© du mouvement vid√©o | M√©trique de fluidit√© du mouvement |
| DynamicDegreeAnalyzer | Qualit√© (Vid√©o) | Mesurer le niveau dynamique et l'amplitude de changement dans la vid√©o | Valeur de degr√© dynamique |
| ImagingQualityAnalyzer | Qualit√© (Vid√©o) | √âvaluation compl√®te de la qualit√© d'imagerie vid√©o | Score de qualit√© d'imagerie |

## Installation

### Configuration de l'environnement

- Python 3.10+
- PyTorch
- Installer les d√©pendances :

```bash
pip install -r requirements.txt
```

*Remarque :* Certains algorithmes peuvent n√©cessiter des √©tapes de configuration suppl√©mentaires. Veuillez vous r√©f√©rer √† la documentation des algorithmes individuels pour les exigences sp√©cifiques.

## D√©marrage rapide

Voici un exemple simple pour vous aider √† d√©marrer avec MarkDiffusion :

```python
import torch
from watermark.auto_watermark import AutoWatermark
from utils.diffusion_config import DiffusionConfig
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

# Configuration du p√©riph√©rique
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# Configuration du pipeline de diffusion
scheduler = DPMSolverMultistepScheduler.from_pretrained("model_path", subfolder="scheduler")
pipe = StableDiffusionPipeline.from_pretrained("model_path", scheduler=scheduler).to(device)
diffusion_config = DiffusionConfig(
    scheduler=scheduler,
    pipe=pipe,
    device=device,
    image_size=(512, 512),
    num_inference_steps=50,
    guidance_scale=7.5,
    gen_seed=42,
    inversion_type="ddim"
)

# Charger l'algorithme de tatouage
watermark = AutoWatermark.load('TR', 
                              algorithm_config='config/TR.json',
                              diffusion_config=diffusion_config)

# G√©n√©rer un m√©dia tatou√©
prompt = "A beautiful sunset over the ocean"
watermarked_image = watermark.generate_watermarked_media(prompt)

# D√©tecter le tatouage
detection_result = watermark.detect_watermark_in_media(watermarked_image)
print(f"Watermark detected: {detection_result}")
```

## Comment utiliser la bo√Æte √† outils

Nous fournissons de nombreux exemples dans `MarkDiffusion_demo.ipynb`.

### G√©n√©ration et d√©tection de m√©dias tatou√©s

#### Cas de g√©n√©ration et de d√©tection de m√©dias tatou√©s

```python
import torch
from watermark.auto_watermark import AutoWatermark
from utils.diffusion_config import DiffusionConfig

# Charger l'algorithme de tatouage
mywatermark = AutoWatermark.load(
    'GS',
    algorithm_config=f'config/GS.json',
    diffusion_config=diffusion_config
)

# G√©n√©rer une image tatou√©e
watermarked_image = mywatermark.generate_watermarked_media(
    input_data="A beautiful landscape with a river and mountains"
)

# Visualiser l'image tatou√©e
watermarked_image.show()

# D√©tecter le tatouage
detection_result = mywatermark.detect_watermark_in_media(watermarked_image)
print(detection_result)
```

### Visualisation des m√©canismes de tatouage

La bo√Æte √† outils comprend des outils de visualisation personnalis√©s qui permettent des vues claires et perspicaces sur le fonctionnement des diff√©rents algorithmes de tatouage dans divers sc√©narios. Ces visualisations aident √† d√©mystifier les m√©canismes des algorithmes, les rendant plus compr√©hensibles pour les utilisateurs.

<img src="img/fig2_visualization_mechanism.png" alt="Watermarking Mechanism Visualization" style="zoom:40%;" />

#### Cas de visualisation du m√©canisme de tatouage

```python
from visualize.auto_visualization import AutoVisualizer

# Obtenir les donn√©es pour la visualisation
data_for_visualization = mywatermark.get_data_for_visualize(watermarked_image)

# Charger le visualiseur
visualizer = AutoVisualizer.load('GS', 
                                data_for_visualization=data_for_visualization)

# Dessiner des diagrammes sur le canevas Matplotlib
fig = visualizer.visualize(rows=2, cols=2, 
                          methods=['draw_watermark_bits', 
                                  'draw_reconstructed_watermark_bits', 
                                  'draw_inverted_latents', 
                                  'draw_inverted_latents_fft'])
```

### Pipelines d'√©valuation

#### Cas d'√©valuation

1. **Pipeline de d√©tection de tatouage**

```python
from evaluation.dataset import StableDiffusionPromptsDataset
from evaluation.pipelines.detection import (
    WatermarkedMediaDetectionPipeline, 
    UnWatermarkedMediaDetectionPipeline, 
    DetectionPipelineReturnType
)
from evaluation.tools.image_editor import JPEGCompression
from evaluation.tools.success_rate_calculator import DynamicThresholdSuccessRateCalculator

# Jeu de donn√©es
my_dataset = StableDiffusionPromptsDataset(max_samples=200)

# Configurer les pipelines de d√©tection
pipeline1 = WatermarkedMediaDetectionPipeline(
    dataset=my_dataset,
    media_editor_list=[JPEGCompression(quality=60)],
    show_progress=True, 
    return_type=DetectionPipelineReturnType.SCORES
)

pipeline2 = UnWatermarkedMediaDetectionPipeline(
    dataset=my_dataset,
    media_editor_list=[],
    show_progress=True, 
    return_type=DetectionPipelineReturnType.SCORES
)

# Configurer les param√®tres de d√©tection
detection_kwargs = {
    "num_inference_steps": 50,
    "guidance_scale": 1.0,
}

# Calculer les taux de r√©ussite
calculator = DynamicThresholdSuccessRateCalculator(
    labels=labels, 
    rule=rules,
    target_fpr=target_fpr
)

results = calculator.calculate(
    pipeline1.evaluate(my_watermark, detection_kwargs=detection_kwargs),
    pipeline2.evaluate(my_watermark, detection_kwargs=detection_kwargs)
)
print(results)
```

2. **Pipeline d'analyse de qualit√© d'image**

```python
from evaluation.dataset import StableDiffusionPromptsDataset, MSCOCODataset
from evaluation.pipelines.image_quality_analysis import (
    DirectImageQualityAnalysisPipeline,
    ReferencedImageQualityAnalysisPipeline,
    GroupImageQualityAnalysisPipeline,
    RepeatImageQualityAnalysisPipeline,
    ComparedImageQualityAnalysisPipeline,
    QualityPipelineReturnType
)
from evaluation.tools.image_quality_analyzer import (
    NIQECalculator, CLIPScoreCalculator, FIDCalculator, 
    InceptionScoreCalculator, LPIPSAnalyzer, PSNRAnalyzer
)

# Exemples de diff√©rentes m√©triques de qualit√© :

# NIQE (√âvaluateur de qualit√© d'image naturelle)
if metric == 'NIQE':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = DirectImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[NIQECalculator()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# Score CLIP
elif metric == 'CLIP':
    my_dataset = MSCOCODataset(max_samples=max_samples)
    pipeline = ReferencedImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[CLIPScoreCalculator()],
        unwatermarked_image_source='generated',
        reference_image_source='natural',
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# FID (Distance d'Inception de Fr√©chet)
elif metric == 'FID':
    my_dataset = MSCOCODataset(max_samples=max_samples)
    pipeline = GroupImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[FIDCalculator()],
        unwatermarked_image_source='generated',
        reference_image_source='natural',
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# IS (Score Inception)
elif metric == 'IS':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = GroupImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[InceptionScoreCalculator()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# LPIPS (Similarit√© de patch d'image perceptuelle apprise)
elif metric == 'LPIPS':
    my_dataset = StableDiffusionPromptsDataset(max_samples=10)
    pipeline = RepeatImageQualityAnalysisPipeline(
        dataset=my_dataset,
        prompt_per_image=20,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[LPIPSAnalyzer()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# PSNR (Rapport signal sur bruit de cr√™te)
elif metric == 'PSNR':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = ComparedImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[PSNRAnalyzer()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# Charger le tatouage et √©valuer
my_watermark = AutoWatermark.load(
    f'{algorithm_name}',
    algorithm_config=f'config/{algorithm_name}.json',
    diffusion_config=diffusion_config
)

print(pipeline.evaluate(my_watermark))
```

3. **Pipeline d'analyse de qualit√© vid√©o**

```python
from evaluation.dataset import VBenchDataset
from evaluation.pipelines.video_quality_analysis import DirectVideoQualityAnalysisPipeline
from evaluation.tools.video_quality_analyzer import (
    SubjectConsistencyAnalyzer,
    MotionSmoothnessAnalyzer,
    DynamicDegreeAnalyzer,
    BackgroundConsistencyAnalyzer,
    ImagingQualityAnalyzer
)

# Charger le jeu de donn√©es VBench
my_dataset = VBenchDataset(max_samples=200, dimension=dimension)

# Initialiser l'analyseur en fonction de la m√©trique
if metric == 'subject_consistency':
    analyzer = SubjectConsistencyAnalyzer(device=device)
elif metric == 'motion_smoothness':
    analyzer = MotionSmoothnessAnalyzer(device=device)
elif metric == 'dynamic_degree':
    analyzer = DynamicDegreeAnalyzer(device=device)
elif metric == 'background_consistency':
    analyzer = BackgroundConsistencyAnalyzer(device=device)
elif metric == 'imaging_quality':
    analyzer = ImagingQualityAnalyzer(device=device)
else:
    raise ValueError(f'Invalid metric: {metric}. Supported metrics: 
                    subject_consistency, motion_smoothness, dynamic_degree,
                    background_consistency, imaging_quality')

# Cr√©er le pipeline d'analyse de qualit√© vid√©o
pipeline = DirectVideoQualityAnalysisPipeline(
    dataset=my_dataset,
    watermarked_video_editor_list=[],
    unwatermarked_video_editor_list=[],
    watermarked_frame_editor_list=[],
    unwatermarked_frame_editor_list=[],
    analyzers=[analyzer],
    show_progress=True,
    return_type=QualityPipelineReturnType.MEAN_SCORES
)

print(pipeline.evaluate(my_watermark))
```

## Citation
```
@article{pan2025markdiffusion,
  title={MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models},
  author={Pan, Leyi and Guan, Sheng and Fu, Zheyu and Si, Luyang and Wang, Zian and Hu, Xuming and King, Irwin and Yu, Philip S and Liu, Aiwei and Wen, Lijie},
  journal={arXiv preprint arXiv:2509.10569},
  year={2025}
}
```

