<div align="center">

<img src="img/markdiffusion-color-1.jpg" style="width: 65%;"/>

# æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¼æ°´å°çš„å¼€æºå·¥å…·åŒ…

[![Homepage](https://img.shields.io/badge/Homepage-5F259F?style=for-the-badge&logo=homepage&logoColor=white)](https://generative-watermark.github.io/)
[![Paper](https://img.shields.io/badge/Paper-A42C25?style=for-the-badge&logo=arxiv&logoColor=white)](https://arxiv.org/abs/2509.10569)
[![HF Models](https://img.shields.io/badge/HF--Models-%23FFD14D?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/Generative-Watermark-Toolkits) 

**è¯­è¨€ç‰ˆæœ¬:** [English](README.md) | [ä¸­æ–‡](README_zh.md) | [FranÃ§ais](README_fr.md)

</div>

> ğŸ”¥ **ä½œä¸ºä¸€ä¸ªæ–°å‘å¸ƒçš„é¡¹ç›®ï¼Œæˆ‘ä»¬æ¬¢è¿ PRï¼** å¦‚æœæ‚¨å·²ç»å®ç°äº† LDM æ°´å°ç®—æ³•æˆ–æœ‰å…´è¶£è´¡çŒ®ä¸€ä¸ªç®—æ³•ï¼Œæˆ‘ä»¬å¾ˆä¹æ„å°†å…¶åŒ…å«åœ¨ MarkDiffusion ä¸­ã€‚åŠ å…¥æˆ‘ä»¬çš„ç¤¾åŒºï¼Œå¸®åŠ©è®©ç”Ÿæˆå¼æ°´å°æŠ€æœ¯å¯¹æ¯ä¸ªäººéƒ½æ›´æ˜“ç”¨ï¼

## ç›®å½•
- [æ³¨æ„äº‹é¡¹](#-æ³¨æ„äº‹é¡¹)
- [æ›´æ–°æ—¥å¿—](#-æ›´æ–°æ—¥å¿—)
- [MarkDiffusion ç®€ä»‹](#markdiffusion-ç®€ä»‹)
  - [æ¦‚è¿°](#æ¦‚è¿°)
  - [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
  - [å·²å®ç°ç®—æ³•](#å·²å®ç°ç®—æ³•)
  - [è¯„ä¼°æ¨¡å—](#è¯„ä¼°æ¨¡å—)
- [å®‰è£…](#å®‰è£…)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [å¦‚ä½•ä½¿ç”¨å·¥å…·åŒ…](#å¦‚ä½•ä½¿ç”¨å·¥å…·åŒ…)
  - [ç”Ÿæˆå’Œæ£€æµ‹æ°´å°åª’ä½“](#ç”Ÿæˆå’Œæ£€æµ‹æ°´å°åª’ä½“)
  - [å¯è§†åŒ–æ°´å°æœºåˆ¶](#å¯è§†åŒ–æ°´å°æœºåˆ¶)
  - [è¯„ä¼°æµæ°´çº¿](#è¯„ä¼°æµæ°´çº¿)
- [å¼•ç”¨](#å¼•ç”¨)

## â—â—â— æ³¨æ„äº‹é¡¹
éšç€ MarkDiffusion ä»“åº“å†…å®¹æ—¥ç›Šä¸°å¯Œä¸”ä½“ç§¯ä¸æ–­å¢å¤§ï¼Œæˆ‘ä»¬åœ¨ Hugging Face ä¸Šåˆ›å»ºäº†ä¸€ä¸ªåä¸º [Generative-Watermark-Toolkits](https://huggingface.co/Generative-Watermark-Toolkits) çš„æ¨¡å‹å­˜å‚¨ä»“åº“ä»¥ä¾¿äºä½¿ç”¨ã€‚è¯¥ä»“åº“åŒ…å«äº†å„ç§æ¶‰åŠè‡ªè®­ç»ƒæ¨¡å‹çš„æ°´å°ç®—æ³•çš„é»˜è®¤æ¨¡å‹ã€‚æˆ‘ä»¬å·²ä»ä¸»ä»“åº“ä¸­è¿™äº›æ°´å°ç®—æ³•å¯¹åº”çš„ `ckpts/` æ–‡ä»¶å¤¹ä¸­ç§»é™¤äº†æ¨¡å‹æƒé‡ã€‚**ä½¿ç”¨ä»£ç æ—¶ï¼Œè¯·é¦–å…ˆæ ¹æ®é…ç½®è·¯å¾„ä» Hugging Face ä»“åº“ä¸‹è½½ç›¸åº”çš„æ¨¡å‹ï¼Œå¹¶å°†å…¶ä¿å­˜åˆ° `ckpts/` ç›®å½•åå†è¿è¡Œä»£ç ã€‚**

## ğŸ”¥ æ›´æ–°æ—¥å¿—
ğŸ¯ **(2025.10.10)** æ·»åŠ  *Maskã€Overlayã€AdaptiveNoiseInjection* å›¾åƒæ”»å‡»å·¥å…·ï¼Œæ„Ÿè°¢ä»˜å“²è¯­çš„ PRï¼

ğŸ¯ **(2025.10.09)** æ·»åŠ  *VideoCodecAttackã€FrameRateAdapterã€FrameInterpolationAttack* è§†é¢‘æ”»å‡»å·¥å…·ï¼Œæ„Ÿè°¢å¸ç’é˜³çš„ PRï¼

ğŸ¯ **(2025.10.08)** æ·»åŠ  *SSIMã€BRISQUEã€VIFã€FSIM* å›¾åƒè´¨é‡åˆ†æå™¨ï¼Œæ„Ÿè°¢ç‹æ¬¢çš„ PRï¼

âœ¨ **(2025.10.07)** æ·»åŠ  [SFW](https://arxiv.org/pdf/2509.07647) æ°´å°æ–¹æ³•ï¼Œæ„Ÿè°¢ç‹æ¬¢çš„ PRï¼

âœ¨ **(2025.10.07)** æ·»åŠ  [VideoMark](https://arxiv.org/abs/2504.16359) æ°´å°æ–¹æ³•ï¼Œæ„Ÿè°¢æç€šè°¦çš„ PRï¼

âœ¨ **(2025.9.29)** æ·»åŠ  [GaussMarker](https://arxiv.org/abs/2506.11444) æ°´å°æ–¹æ³•ï¼Œæ„Ÿè°¢å¸ç’é˜³çš„ PRï¼

## MarkDiffusion ç®€ä»‹

### æ¦‚è¿°

MarkDiffusion æ˜¯ä¸€ä¸ªç”¨äºæ½œåœ¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¼æ°´å°çš„å¼€æº Python å·¥å…·åŒ…ã€‚éšç€åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹åº”ç”¨èŒƒå›´çš„æ‰©å¤§ï¼Œç¡®ä¿ç”Ÿæˆåª’ä½“çš„çœŸå®æ€§å’Œæ¥æºå˜å¾—è‡³å…³é‡è¦ã€‚MarkDiffusion ç®€åŒ–äº†æ°´å°æŠ€æœ¯çš„è®¿é—®ã€ç†è§£å’Œè¯„ä¼°ï¼Œä½¿ç ”ç©¶äººå‘˜å’Œæ›´å¹¿æ³›çš„ç¤¾åŒºéƒ½èƒ½è½»æ¾ä½¿ç”¨ã€‚*æ³¨æ„ï¼šå¦‚æœæ‚¨å¯¹ LLM æ°´å°ï¼ˆæ–‡æœ¬æ°´å°ï¼‰æ„Ÿå…´è¶£ï¼Œè¯·å‚è€ƒæˆ‘ä»¬å›¢é˜Ÿçš„ [MarkLLM](https://github.com/THU-BPM/MarkLLM) å·¥å…·åŒ…ã€‚*

è¯¥å·¥å…·åŒ…åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šç»Ÿä¸€çš„å®ç°æ¡†æ¶ï¼Œç”¨äºç®€åŒ–æ°´å°ç®—æ³•é›†æˆå’Œç”¨æˆ·å‹å¥½çš„ç•Œé¢ï¼›æœºåˆ¶å¯è§†åŒ–å¥—ä»¶ï¼Œç›´è§‚åœ°å±•ç¤ºæ·»åŠ å’Œæå–çš„æ°´å°æ¨¡å¼ï¼Œå¸®åŠ©å…¬ä¼—ç†è§£ï¼›ä»¥åŠå…¨é¢çš„è¯„ä¼°æ¨¡å—ï¼Œæä¾› 24 ä¸ªå·¥å…·çš„æ ‡å‡†å®ç°ï¼Œæ¶µç›–ä¸‰ä¸ªå…³é”®æ–¹é¢â€”â€”å¯æ£€æµ‹æ€§ã€é²æ£’æ€§å’Œè¾“å‡ºè´¨é‡ï¼Œä»¥åŠ 8 ä¸ªè‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿ã€‚

<img src="img/fig1_overview.png" alt="MarkDiffusion Overview" style="zoom:50%;" />

### æ ¸å¿ƒç‰¹æ€§

- **ç»Ÿä¸€å®ç°æ¡†æ¶ï¼š** MarkDiffusion æä¾›äº†ä¸€ä¸ªæ¨¡å—åŒ–æ¶æ„ï¼Œæ”¯æŒå…«ç§æœ€å…ˆè¿›çš„ LDM ç”Ÿæˆå¼å›¾åƒ/è§†é¢‘æ°´å°ç®—æ³•ã€‚

- **å…¨é¢çš„ç®—æ³•æ”¯æŒï¼š** ç›®å‰å®ç°äº†æ¥è‡ªä¸¤å¤§ç±»åˆ«çš„ 8 ç§æ°´å°ç®—æ³•ï¼šåŸºäºæ¨¡å¼çš„æ–¹æ³•ï¼ˆTree-Ringã€Ring-IDã€ROBINã€WINDï¼‰å’ŒåŸºäºå¯†é’¥çš„æ–¹æ³•ï¼ˆGaussian-Shadingã€PRCã€SEALã€VideoShieldï¼‰ã€‚

- **å¯è§†åŒ–è§£å†³æ–¹æ¡ˆï¼š** è¯¥å·¥å…·åŒ…åŒ…å«å®šåˆ¶çš„å¯è§†åŒ–å·¥å…·ï¼Œèƒ½å¤Ÿæ¸…æ™°è€Œæ·±å…¥åœ°å±•ç¤ºä¸åŒæ°´å°ç®—æ³•åœ¨å„ç§åœºæ™¯ä¸‹çš„è¿è¡Œæ–¹å¼ã€‚è¿™äº›å¯è§†åŒ–æœ‰åŠ©äºæ­ç¤ºç®—æ³•æœºåˆ¶ï¼Œä½¿å…¶å¯¹ç”¨æˆ·æ›´æ˜“ç†è§£ã€‚

- **è¯„ä¼°æ¨¡å—ï¼š** æ‹¥æœ‰ 20 ä¸ªè¯„ä¼°å·¥å…·ï¼Œæ¶µç›–å¯æ£€æµ‹æ€§ã€é²æ£’æ€§å’Œå¯¹è¾“å‡ºè´¨é‡çš„å½±å“ï¼ŒMarkDiffusion æä¾›å…¨é¢çš„è¯„ä¼°èƒ½åŠ›ã€‚å®ƒå…·æœ‰ 5 ä¸ªè‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿ï¼šæ°´å°æ£€æµ‹æµæ°´çº¿ã€å›¾åƒè´¨é‡åˆ†ææµæ°´çº¿ã€è§†é¢‘è´¨é‡åˆ†ææµæ°´çº¿ä»¥åŠä¸“é—¨çš„é²æ£’æ€§è¯„ä¼°å·¥å…·ã€‚

### å·²å®ç°ç®—æ³•

| **ç®—æ³•** | **ç±»åˆ«** | **ç›®æ ‡** | **å‚è€ƒæ–‡çŒ®** |
|---------------|-------------|------------|---------------|
| Tree-Ring | æ¨¡å¼ | å›¾åƒ | [Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030) |
| Ring-ID | æ¨¡å¼ | å›¾åƒ | [RingID: Rethinking Tree-Ring Watermarking for Enhanced Multi-Key Identification](https://arxiv.org/abs/2404.14055) |
| ROBIN | æ¨¡å¼ | å›¾åƒ | [ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization](https://arxiv.org/abs/2411.03862) |
| WIND | æ¨¡å¼ | å›¾åƒ | [Hidden in the Noise: Two-Stage Robust Watermarking for Images](https://arxiv.org/abs/2412.04653) |
| SFW | æ¨¡å¼ | å›¾åƒ | [Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity](https://arxiv.org/abs/2509.07647) |
| Gaussian-Shading | å¯†é’¥ | å›¾åƒ | [Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956) |
| GaussMarker | å¯†é’¥ | å›¾åƒ | [GaussMarker: Robust Dual-Domain Watermark for Diffusion Models](https://arxiv.org/abs/2506.11444) |
| PRC | å¯†é’¥ | å›¾åƒ | [An undetectable watermark for generative image models](https://arxiv.org/abs/2410.07369) |
| SEAL | å¯†é’¥ | å›¾åƒ | [SEAL: Semantic Aware Image Watermarking](https://arxiv.org/abs/2503.12172) |
| VideoShield | å¯†é’¥ | è§†é¢‘ | [VideoShield: Regulating Diffusion-based Video Generation Models via Watermarking](https://arxiv.org/abs/2501.14195) |
| VideoMark | å¯†é’¥ | è§†é¢‘ | [VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models](https://arxiv.org/abs/2504.16359) |

### è¯„ä¼°æ¨¡å—
#### è¯„ä¼°æµæ°´çº¿

MarkDiffusion æ”¯æŒå…«ä¸ªæµæ°´çº¿ï¼Œä¸¤ä¸ªç”¨äºæ£€æµ‹ï¼ˆWatermarkedMediaDetectionPipeline å’Œ UnWatermarkedMediaDetectionPipelineï¼‰ï¼Œå…­ä¸ªç”¨äºè´¨é‡åˆ†æã€‚ä¸‹è¡¨è¯¦ç»†è¯´æ˜äº†è´¨é‡åˆ†ææµæ°´çº¿ã€‚

| **è´¨é‡åˆ†ææµæ°´çº¿** | **è¾“å…¥ç±»å‹** | **æ‰€éœ€æ•°æ®** | **é€‚ç”¨æŒ‡æ ‡** |  
| --- | --- | --- | --- |
| DirectImageQualityAnalysisPipeline | å•å¼ å›¾åƒ | ç”Ÿæˆçš„æœ‰/æ— æ°´å°å›¾åƒ | å•å¼ å›¾åƒè¯„ä¼°æŒ‡æ ‡ | 
| ReferencedImageQualityAnalysisPipeline | å›¾åƒ + å‚è€ƒå†…å®¹ | ç”Ÿæˆçš„æœ‰/æ— æ°´å°å›¾åƒ + å‚è€ƒå›¾åƒ/æ–‡æœ¬ | éœ€è¦åœ¨å•å¼ å›¾åƒå’Œå‚è€ƒå†…å®¹ï¼ˆæ–‡æœ¬/å›¾åƒï¼‰ä¹‹é—´è®¡ç®—çš„æŒ‡æ ‡ | 
| GroupImageQualityAnalysisPipeline | å›¾åƒé›†ï¼ˆ+ å‚è€ƒå›¾åƒé›†ï¼‰ | ç”Ÿæˆçš„æœ‰/æ— æ°´å°å›¾åƒé›†ï¼ˆ+ å‚è€ƒå›¾åƒé›†ï¼‰ | éœ€è¦åœ¨å›¾åƒé›†ä¸Šè®¡ç®—çš„æŒ‡æ ‡ | 
| RepeatImageQualityAnalysisPipeline | å›¾åƒé›† | é‡å¤ç”Ÿæˆçš„æœ‰/æ— æ°´å°å›¾åƒé›† | ç”¨äºè¯„ä¼°é‡å¤ç”Ÿæˆå›¾åƒé›†çš„æŒ‡æ ‡ | 
| ComparedImageQualityAnalysisPipeline | ä¸¤å¼ å¯¹æ¯”å›¾åƒ | ç”Ÿæˆçš„æœ‰æ°´å°å’Œæ— æ°´å°å›¾åƒ | æµ‹é‡ä¸¤å¼ å›¾åƒä¹‹é—´å·®å¼‚çš„æŒ‡æ ‡ | 
| DirectVideoQualityAnalysisPipeline | å•ä¸ªè§†é¢‘ | ç”Ÿæˆçš„è§†é¢‘å¸§é›† | æ•´ä½“è§†é¢‘è¯„ä¼°æŒ‡æ ‡ |

#### è¯„ä¼°å·¥å…·

| **å·¥å…·åç§°** | **è¯„ä¼°ç±»åˆ«** | **åŠŸèƒ½æè¿°** | **è¾“å‡ºæŒ‡æ ‡** |
| --- | --- | --- | --- |
| FundamentalSuccessRateCalculator | å¯æ£€æµ‹æ€§ | è®¡ç®—å›ºå®šé˜ˆå€¼æ°´å°æ£€æµ‹çš„åˆ†ç±»æŒ‡æ ‡ | å„ç§åˆ†ç±»æŒ‡æ ‡ |
| DynamicThresholdSuccessRateCalculator | å¯æ£€æµ‹æ€§ | è®¡ç®—åŠ¨æ€é˜ˆå€¼æ°´å°æ£€æµ‹çš„åˆ†ç±»æŒ‡æ ‡ | å„ç§åˆ†ç±»æŒ‡æ ‡ |
| **å›¾åƒæ”»å‡»å·¥å…·** | | | |
| Rotation | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | å›¾åƒæ—‹è½¬æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹æ—‹è½¬å˜æ¢çš„æŠ—æ€§ | æ—‹è½¬åçš„å›¾åƒ/å¸§ |
| CrScï¼ˆè£å‰ªä¸ç¼©æ”¾ï¼‰ | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | è£å‰ªå’Œç¼©æ”¾æ”»å‡»ï¼Œè¯„ä¼°æ°´å°å¯¹å°ºå¯¸å˜åŒ–çš„é²æ£’æ€§ | è£å‰ª/ç¼©æ”¾åçš„å›¾åƒ/å¸§ |
| GaussianNoise | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | é«˜æ–¯å™ªå£°æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹å™ªå£°å¹²æ‰°çš„æŠ—æ€§ | å™ªå£°æŸåçš„å›¾åƒ/å¸§ |
| GaussianBlurring | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | é«˜æ–¯æ¨¡ç³Šæ”»å‡»ï¼Œè¯„ä¼°æ°´å°å¯¹æ¨¡ç³Šå¤„ç†çš„æŠ—æ€§ | æ¨¡ç³Šåçš„å›¾åƒ/å¸§ |
| JPEGCompression | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | JPEG å‹ç¼©æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹æœ‰æŸå‹ç¼©çš„é²æ£’æ€§ | å‹ç¼©åçš„å›¾åƒ/å¸§ |
| Brightness | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | äº®åº¦è°ƒæ•´æ”»å‡»ï¼Œè¯„ä¼°æ°´å°å¯¹äº®åº¦å˜åŒ–çš„æŠ—æ€§ | äº®åº¦ä¿®æ”¹åçš„å›¾åƒ/å¸§ |
| Mask | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | å›¾åƒé®ç½©æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹éšæœºé»‘è‰²çŸ©å½¢éƒ¨åˆ†é®æŒ¡çš„æŠ—æ€§ | é®ç½©åçš„å›¾åƒ/å¸§ |
| Overlay | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | å›¾åƒè¦†ç›–æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹æ¶‚é¸¦å¼ç¬”è§¦å’Œæ³¨é‡Šçš„æŠ—æ€§ | è¦†ç›–åçš„å›¾åƒ/å¸§ |
| AdaptiveNoiseInjection | é²æ£’æ€§ï¼ˆå›¾åƒï¼‰ | è‡ªé€‚åº”å™ªå£°æ³¨å…¥æ”»å‡»ï¼Œæµ‹è¯•æ°´å°å¯¹å†…å®¹æ„ŸçŸ¥å™ªå£°çš„æŠ—æ€§ï¼ˆé«˜æ–¯/æ¤’ç›/æ³Šæ¾/æ–‘ç‚¹ï¼‰ | è‡ªé€‚åº”å™ªå£°å¤„ç†åçš„å›¾åƒ/å¸§ |
| **è§†é¢‘æ”»å‡»å·¥å…·** | | | |
| MPEG4Compression | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | MPEG-4 è§†é¢‘å‹ç¼©æ”»å‡»ï¼Œæµ‹è¯•è§†é¢‘æ°´å°çš„å‹ç¼©é²æ£’æ€§ | å‹ç¼©åçš„è§†é¢‘å¸§ |
| FrameAverage | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | å¸§å¹³å‡æ”»å‡»ï¼Œé€šè¿‡å¸§é—´å¹³å‡ç ´åæ°´å° | å¹³å‡åçš„è§†é¢‘å¸§ |
| FrameSwap | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | å¸§äº¤æ¢æ”»å‡»ï¼Œé€šè¿‡æ”¹å˜å¸§åºåˆ—æµ‹è¯•é²æ£’æ€§ | äº¤æ¢åçš„è§†é¢‘å¸§ |
| VideoCodecAttack | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | ç¼–è§£ç å™¨é‡ç¼–ç æ”»å‡»ï¼Œæ¨¡æ‹Ÿå¹³å°è½¬ç ï¼ˆH.264/H.265/VP9/AV1ï¼‰ | é‡ç¼–ç åçš„è§†é¢‘å¸§ |
| FrameRateAdapter | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | å¸§ç‡è½¬æ¢æ”»å‡»ï¼Œåœ¨ä¿æŒæ—¶é•¿çš„åŒæ—¶é‡é‡‡æ ·å¸§ | é‡é‡‡æ ·åçš„å¸§åºåˆ— |
| FrameInterpolationAttack | é²æ£’æ€§ï¼ˆè§†é¢‘ï¼‰ | å¸§æ’å€¼æ”»å‡»ï¼Œæ’å…¥æ··åˆå¸§ä»¥æ”¹å˜æ—¶é—´å¯†åº¦ | æ’å€¼åçš„è§†é¢‘å¸§ |
| **å›¾åƒè´¨é‡åˆ†æå™¨** | | | |
| InceptionScoreCalculator | è´¨é‡ï¼ˆå›¾åƒï¼‰ | è¯„ä¼°ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§ | IS åˆ†æ•° |
| FIDCalculator | è´¨é‡ï¼ˆå›¾åƒï¼‰ | FrÃ©chet Inception Distanceï¼Œæµ‹é‡ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ | FID å€¼ |
| LPIPSAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | å­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼åº¦ï¼Œè¯„ä¼°æ„ŸçŸ¥è´¨é‡ | LPIPS è·ç¦» |
| CLIPScoreCalculator | è´¨é‡ï¼ˆå›¾åƒï¼‰ | åŸºäº CLIP çš„æ–‡æœ¬-å›¾åƒä¸€è‡´æ€§è¯„ä¼° | CLIP ç›¸ä¼¼åº¦åˆ†æ•° |
| PSNRAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | å³°å€¼ä¿¡å™ªæ¯”ï¼Œæµ‹é‡å›¾åƒå¤±çœŸ | PSNR å€¼ï¼ˆdBï¼‰ |
| NIQECalculator | è´¨é‡ï¼ˆå›¾åƒï¼‰ | è‡ªç„¶å›¾åƒè´¨é‡è¯„ä¼°å™¨ï¼Œæ— å‚è€ƒè´¨é‡è¯„ä¼° | NIQE åˆ†æ•° |
| SSIMAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | ä¸¤å¼ å›¾åƒä¹‹é—´çš„ç»“æ„ç›¸ä¼¼æ€§æŒ‡æ•° | SSIM å€¼ |
| BRISQUEAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | ç›²/æ— å‚è€ƒå›¾åƒç©ºé—´è´¨é‡è¯„ä¼°å™¨ï¼Œæ— éœ€å‚è€ƒå³å¯è¯„ä¼°å›¾åƒçš„æ„ŸçŸ¥è´¨é‡ | BRISQUE åˆ†æ•° |
| VIFAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | è§†è§‰ä¿¡æ¯ä¿çœŸåº¦åˆ†æå™¨ï¼Œæ¯”è¾ƒå¤±çœŸå›¾åƒä¸å‚è€ƒå›¾åƒä»¥é‡åŒ–ä¿ç•™çš„è§†è§‰ä¿¡æ¯é‡ | VIF å€¼ |
| FSIMAnalyzer | è´¨é‡ï¼ˆå›¾åƒï¼‰ | ç‰¹å¾ç›¸ä¼¼æ€§æŒ‡æ•°åˆ†æå™¨ï¼ŒåŸºäºç›¸ä½ä¸€è‡´æ€§å’Œæ¢¯åº¦å¹…åº¦æ¯”è¾ƒä¸¤å¼ å›¾åƒçš„ç»“æ„ç›¸ä¼¼æ€§ | FSIM å€¼ |
| **è§†é¢‘è´¨é‡åˆ†æå™¨** | | | |
| SubjectConsistencyAnalyzer | è´¨é‡ï¼ˆè§†é¢‘ï¼‰ | è¯„ä¼°è§†é¢‘ä¸­ä¸»ä½“å¯¹è±¡çš„ä¸€è‡´æ€§ | ä¸»ä½“ä¸€è‡´æ€§åˆ†æ•° |
| BackgroundConsistencyAnalyzer | è´¨é‡ï¼ˆè§†é¢‘ï¼‰ | è¯„ä¼°è§†é¢‘ä¸­èƒŒæ™¯çš„è¿è´¯æ€§å’Œç¨³å®šæ€§ | èƒŒæ™¯ä¸€è‡´æ€§åˆ†æ•° |
| MotionSmoothnessAnalyzer | è´¨é‡ï¼ˆè§†é¢‘ï¼‰ | è¯„ä¼°è§†é¢‘è¿åŠ¨çš„å¹³æ»‘åº¦ | è¿åŠ¨å¹³æ»‘åº¦æŒ‡æ ‡ |
| DynamicDegreeAnalyzer | è´¨é‡ï¼ˆè§†é¢‘ï¼‰ | æµ‹é‡è§†é¢‘ä¸­çš„åŠ¨æ€æ°´å¹³å’Œå˜åŒ–å¹…åº¦ | åŠ¨æ€åº¦å€¼ |
| ImagingQualityAnalyzer | è´¨é‡ï¼ˆè§†é¢‘ï¼‰ | ç»¼åˆè¯„ä¼°è§†é¢‘æˆåƒè´¨é‡ | æˆåƒè´¨é‡åˆ†æ•° |

## å®‰è£…

### ç¯å¢ƒè®¾ç½®

- Python 3.10+
- PyTorch
- å®‰è£…ä¾èµ–ï¼š

```bash
pip install -r requirements.txt
```

*æ³¨æ„ï¼š* æŸäº›ç®—æ³•å¯èƒ½éœ€è¦é¢å¤–çš„è®¾ç½®æ­¥éª¤ã€‚è¯·å‚è€ƒå„ä¸ªç®—æ³•æ–‡æ¡£äº†è§£å…·ä½“è¦æ±‚ã€‚

## å¿«é€Ÿå¼€å§‹

è¿™é‡Œæœ‰ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨ MarkDiffusionï¼š

```python
import torch
from watermark.auto_watermark import AutoWatermark
from utils.diffusion_config import DiffusionConfig
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler

# è®¾å¤‡è®¾ç½®
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# é…ç½®æ‰©æ•£æµæ°´çº¿
scheduler = DPMSolverMultistepScheduler.from_pretrained("model_path", subfolder="scheduler")
pipe = StableDiffusionPipeline.from_pretrained("model_path", scheduler=scheduler).to(device)
diffusion_config = DiffusionConfig(
    scheduler=scheduler,
    pipe=pipe,
    device=device,
    image_size=(512, 512),
    num_inference_steps=50,
    guidance_scale=7.5,
    gen_seed=42,
    inversion_type="ddim"
)

# åŠ è½½æ°´å°ç®—æ³•
watermark = AutoWatermark.load('TR', 
                              algorithm_config='config/TR.json',
                              diffusion_config=diffusion_config)

# ç”Ÿæˆå¸¦æ°´å°çš„åª’ä½“
prompt = "A beautiful sunset over the ocean"
watermarked_image = watermark.generate_watermarked_media(prompt)

# æ£€æµ‹æ°´å°
detection_result = watermark.detect_watermark_in_media(watermarked_image)
print(f"Watermark detected: {detection_result}")
```

## å¦‚ä½•ä½¿ç”¨å·¥å…·åŒ…

æˆ‘ä»¬åœ¨ `MarkDiffusion_demo.ipynb` ä¸­æä¾›äº†å¤§é‡ç¤ºä¾‹ã€‚

### ç”Ÿæˆå’Œæ£€æµ‹æ°´å°åª’ä½“

#### ç”Ÿæˆå’Œæ£€æµ‹æ°´å°åª’ä½“çš„æ¡ˆä¾‹

```python
import torch
from watermark.auto_watermark import AutoWatermark
from utils.diffusion_config import DiffusionConfig

# åŠ è½½æ°´å°ç®—æ³•
mywatermark = AutoWatermark.load(
    'GS',
    algorithm_config=f'config/GS.json',
    diffusion_config=diffusion_config
)

# ç”Ÿæˆå¸¦æ°´å°çš„å›¾åƒ
watermarked_image = mywatermark.generate_watermarked_media(
    input_data="A beautiful landscape with a river and mountains"
)

# å¯è§†åŒ–å¸¦æ°´å°çš„å›¾åƒ
watermarked_image.show()

# æ£€æµ‹æ°´å°
detection_result = mywatermark.detect_watermark_in_media(watermarked_image)
print(detection_result)
```

### å¯è§†åŒ–æ°´å°æœºåˆ¶

è¯¥å·¥å…·åŒ…åŒ…å«å®šåˆ¶çš„å¯è§†åŒ–å·¥å…·ï¼Œèƒ½å¤Ÿæ¸…æ™°è€Œæ·±å…¥åœ°å±•ç¤ºä¸åŒæ°´å°ç®—æ³•åœ¨å„ç§åœºæ™¯ä¸‹çš„è¿è¡Œæ–¹å¼ã€‚è¿™äº›å¯è§†åŒ–æœ‰åŠ©äºæ­ç¤ºç®—æ³•æœºåˆ¶ï¼Œä½¿å…¶å¯¹ç”¨æˆ·æ›´æ˜“ç†è§£ã€‚

<img src="img/fig2_visualization_mechanism.png" alt="Watermarking Mechanism Visualization" style="zoom:40%;" />

#### å¯è§†åŒ–æ°´å°æœºåˆ¶çš„æ¡ˆä¾‹

```python
from visualize.auto_visualization import AutoVisualizer

# è·å–ç”¨äºå¯è§†åŒ–çš„æ•°æ®
data_for_visualization = mywatermark.get_data_for_visualize(watermarked_image)

# åŠ è½½å¯è§†åŒ–å™¨
visualizer = AutoVisualizer.load('GS', 
                                data_for_visualization=data_for_visualization)

# åœ¨ Matplotlib ç”»å¸ƒä¸Šç»˜åˆ¶å›¾è¡¨
fig = visualizer.visualize(rows=2, cols=2, 
                          methods=['draw_watermark_bits', 
                                  'draw_reconstructed_watermark_bits', 
                                  'draw_inverted_latents', 
                                  'draw_inverted_latents_fft'])
```

### è¯„ä¼°æµæ°´çº¿

#### è¯„ä¼°æ¡ˆä¾‹

1. **æ°´å°æ£€æµ‹æµæ°´çº¿**

```python
from evaluation.dataset import StableDiffusionPromptsDataset
from evaluation.pipelines.detection import (
    WatermarkedMediaDetectionPipeline, 
    UnWatermarkedMediaDetectionPipeline, 
    DetectionPipelineReturnType
)
from evaluation.tools.image_editor import JPEGCompression
from evaluation.tools.success_rate_calculator import DynamicThresholdSuccessRateCalculator

# æ•°æ®é›†
my_dataset = StableDiffusionPromptsDataset(max_samples=200)

# è®¾ç½®æ£€æµ‹æµæ°´çº¿
pipeline1 = WatermarkedMediaDetectionPipeline(
    dataset=my_dataset,
    media_editor_list=[JPEGCompression(quality=60)],
    show_progress=True, 
    return_type=DetectionPipelineReturnType.SCORES
)

pipeline2 = UnWatermarkedMediaDetectionPipeline(
    dataset=my_dataset,
    media_editor_list=[],
    show_progress=True, 
    return_type=DetectionPipelineReturnType.SCORES
)

# é…ç½®æ£€æµ‹å‚æ•°
detection_kwargs = {
    "num_inference_steps": 50,
    "guidance_scale": 1.0,
}

# è®¡ç®—æˆåŠŸç‡
calculator = DynamicThresholdSuccessRateCalculator(
    labels=labels, 
    rule=rules,
    target_fpr=target_fpr
)

results = calculator.calculate(
    pipeline1.evaluate(my_watermark, detection_kwargs=detection_kwargs),
    pipeline2.evaluate(my_watermark, detection_kwargs=detection_kwargs)
)
print(results)
```

2. **å›¾åƒè´¨é‡åˆ†ææµæ°´çº¿**

```python
from evaluation.dataset import StableDiffusionPromptsDataset, MSCOCODataset
from evaluation.pipelines.image_quality_analysis import (
    DirectImageQualityAnalysisPipeline,
    ReferencedImageQualityAnalysisPipeline,
    GroupImageQualityAnalysisPipeline,
    RepeatImageQualityAnalysisPipeline,
    ComparedImageQualityAnalysisPipeline,
    QualityPipelineReturnType
)
from evaluation.tools.image_quality_analyzer import (
    NIQECalculator, CLIPScoreCalculator, FIDCalculator, 
    InceptionScoreCalculator, LPIPSAnalyzer, PSNRAnalyzer
)

# ä¸åŒè´¨é‡æŒ‡æ ‡çš„ç¤ºä¾‹ï¼š

# NIQEï¼ˆæ— å‚è€ƒå›¾åƒè´¨é‡è¯„ä¼°å™¨ï¼‰
if metric == 'NIQE':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = DirectImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[NIQECalculator()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# CLIP åˆ†æ•°
elif metric == 'CLIP':
    my_dataset = MSCOCODataset(max_samples=max_samples)
    pipeline = ReferencedImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[CLIPScoreCalculator()],
        unwatermarked_image_source='generated',
        reference_image_source='natural',
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# FIDï¼ˆFrÃ©chet Inception Distanceï¼‰
elif metric == 'FID':
    my_dataset = MSCOCODataset(max_samples=max_samples)
    pipeline = GroupImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[FIDCalculator()],
        unwatermarked_image_source='generated',
        reference_image_source='natural',
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# ISï¼ˆInception Scoreï¼‰
elif metric == 'IS':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = GroupImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[InceptionScoreCalculator()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# LPIPSï¼ˆå­¦ä¹ æ„ŸçŸ¥å›¾åƒå—ç›¸ä¼¼åº¦ï¼‰
elif metric == 'LPIPS':
    my_dataset = StableDiffusionPromptsDataset(max_samples=10)
    pipeline = RepeatImageQualityAnalysisPipeline(
        dataset=my_dataset,
        prompt_per_image=20,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[LPIPSAnalyzer()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# PSNRï¼ˆå³°å€¼ä¿¡å™ªæ¯”ï¼‰
elif metric == 'PSNR':
    my_dataset = StableDiffusionPromptsDataset(max_samples=max_samples)
    pipeline = ComparedImageQualityAnalysisPipeline(
        dataset=my_dataset,
        watermarked_image_editor_list=[],
        unwatermarked_image_editor_list=[],
        analyzers=[PSNRAnalyzer()],
        show_progress=True,
        return_type=QualityPipelineReturnType.MEAN_SCORES
    )

# åŠ è½½æ°´å°å¹¶è¯„ä¼°
my_watermark = AutoWatermark.load(
    f'{algorithm_name}',
    algorithm_config=f'config/{algorithm_name}.json',
    diffusion_config=diffusion_config
)

print(pipeline.evaluate(my_watermark))
```

3. **è§†é¢‘è´¨é‡åˆ†ææµæ°´çº¿**

```python
from evaluation.dataset import VBenchDataset
from evaluation.pipelines.video_quality_analysis import DirectVideoQualityAnalysisPipeline
from evaluation.tools.video_quality_analyzer import (
    SubjectConsistencyAnalyzer,
    MotionSmoothnessAnalyzer,
    DynamicDegreeAnalyzer,
    BackgroundConsistencyAnalyzer,
    ImagingQualityAnalyzer
)

# åŠ è½½ VBench æ•°æ®é›†
my_dataset = VBenchDataset(max_samples=200, dimension=dimension)

# æ ¹æ®æŒ‡æ ‡åˆå§‹åŒ–åˆ†æå™¨
if metric == 'subject_consistency':
    analyzer = SubjectConsistencyAnalyzer(device=device)
elif metric == 'motion_smoothness':
    analyzer = MotionSmoothnessAnalyzer(device=device)
elif metric == 'dynamic_degree':
    analyzer = DynamicDegreeAnalyzer(device=device)
elif metric == 'background_consistency':
    analyzer = BackgroundConsistencyAnalyzer(device=device)
elif metric == 'imaging_quality':
    analyzer = ImagingQualityAnalyzer(device=device)
else:
    raise ValueError(f'Invalid metric: {metric}. Supported metrics: 
                    subject_consistency, motion_smoothness, dynamic_degree,
                    background_consistency, imaging_quality')

# åˆ›å»ºè§†é¢‘è´¨é‡åˆ†ææµæ°´çº¿
pipeline = DirectVideoQualityAnalysisPipeline(
    dataset=my_dataset,
    watermarked_video_editor_list=[],
    unwatermarked_video_editor_list=[],
    watermarked_frame_editor_list=[],
    unwatermarked_frame_editor_list=[],
    analyzers=[analyzer],
    show_progress=True,
    return_type=QualityPipelineReturnType.MEAN_SCORES
)

print(pipeline.evaluate(my_watermark))
```

## å¼•ç”¨
```
@article{pan2025markdiffusion,
  title={MarkDiffusion: An Open-Source Toolkit for Generative Watermarking of Latent Diffusion Models},
  author={Pan, Leyi and Guan, Sheng and Fu, Zheyu and Si, Luyang and Wang, Zian and Hu, Xuming and King, Irwin and Yu, Philip S and Liu, Aiwei and Wen, Lijie},
  journal={arXiv preprint arXiv:2509.10569},
  year={2025}
}
```

